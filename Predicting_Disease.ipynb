{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>Radius_mean</th>\n",
       "      <th>Texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>21.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  Radius_mean  Texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         21.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data-cancer.csv')\n",
    "df = pd.read_csv('data-cancer.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE ARE TRYING TO PREDICT THE DIAGNOSIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = data['diagnosis'].groupby(data['diagnosis']).count()\n",
    "sns.barplot(x=A.index, y= A.values , data= data)\n",
    "plt.title('Distribution of Diagnosis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT THE DIAGNOSIS VARIAVBLES TO 0 AND 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>Radius_mean</th>\n",
       "      <th>Texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>21.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  Radius_mean  Texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         21.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['diagnosis'] = data['diagnosis'].map({'M':1, 'B': 0})\n",
    "del data['id']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.loc[:, data.columns[1:]]\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score =  0.9035087719298246\n",
      "cfn report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        67\n",
      "           1       0.85      0.94      0.89        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.91      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score = ', accuracy_score(y_test, y_pred))\n",
    "print('cfn report', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE FROM THE DECISION TREE METHOD WE HAVE AN ACCURACY OF 90.4%, LETS TRY THE CROSS_VALUE_METHOD:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score =  0.9035087719298246\n",
      "cfn report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        67\n",
      "           1       0.85      0.94      0.89        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.91      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for depth in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    dt.fit(x_train, y_train)\n",
    "    Training_A = accuracy_score(y_train, dt.predict(x_train))\n",
    "   \n",
    "print('accuracy score = ', accuracy_score(y_test, y_pred))\n",
    "print('cfn report', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUR ACCURACY SCORE HAS SLIGHTLY INCREASED TO 91%, NOW LETS TRY THE XBO0ST METHOD:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XGBClassifier()\n",
    "xg.fit(x_train, y_train)\n",
    "y_hat = xg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score =  0.9824561403508771\n",
      "cfn report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        67\n",
      "           1       1.00      0.96      0.98        47\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score = ', accuracy_score(y_test, y_hat))\n",
    "print('cfn report', classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE FOR THE XGBOOST OUR ACCURACY INCREASED SIGNIFCANTLY TO 98% WHICH IS EXCELLENT, NOW LETS TRY GRIDSEARCHCV METHOD:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .........................gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=0, learning_rate=1; total time=   0.0s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.2s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.2s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.2s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=0, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...........................gamma=1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ........................gamma=1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.2s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.2s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END .......................gamma=1, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ........................gamma=10, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.1s\n",
      "[CV] END ..........................gamma=10, learning_rate=1; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .......................gamma=10, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.1s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END ......................gamma=10, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .......................gamma=100, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.1s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.1s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.0s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.1s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.2s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.0s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.1s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.0s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.0s\n",
      "[CV] END .........................gamma=100, learning_rate=1; total time=   0.0s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ......................gamma=100, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n",
      "[CV] END .....................gamma=100, learning_rate=0.001; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;gamma&#x27;: [0, 1, 10, 100],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 1, 0.01, 0.001]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;gamma&#x27;: [0, 1, 10, 100],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 1, 0.01, 0.001]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_bin=None,\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'gamma': [0, 1, 10, 100],\n",
       "                         'learning_rate': [0.1, 1, 0.01, 0.001]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = { 'learning_rate' :[0.1, 1, 0.01, 0.001], 'gamma' : [0, 1, 10, 100]}\n",
    "model = GridSearchCV(xg, grid, cv = 10, verbose= 2)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score =  0.9649122807017544\n",
      "cfn report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        67\n",
      "           1       0.98      0.94      0.96        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predict = model.predict(x_test)\n",
    "print('accuracy score = ', accuracy_score(y_test, grid_predict))\n",
    "print('cfn report', classification_report(y_test, grid_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE THE GRIDSEARCH METHOD GAVE US ACCURACY OF 96.5%, HOWEVER XGBOOST METHOD IS STILL SUPERIOR WITH 98% ACCURACY ON PREDICTING THE DISEASE!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
